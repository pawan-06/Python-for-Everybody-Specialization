{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Mu1.png)\n",
    "**PAWAN KUMAR**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Databases with Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**by University of Michigan**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WEEK_1 Object Oriented Python (Chapter 14)\n",
    "Assignment : only quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WEEK_2 Basic Structured Query Language (Chapter 15)\n",
    "**Assignment_15.1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a SQLITE database or use an existing database and create a table in the database called \"Ages\":**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE TABLE Ages ( \n",
    "  name VARCHAR(128), \n",
    "  age INTEGER\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Then make sure the table is empty by deleting any rows that you previously inserted, and insert these rows and only these rows with the following commands:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DELETE FROM Ages;\n",
    "INSERT INTO Ages (name, age) VALUES ('Nana', 18);\n",
    "INSERT INTO Ages (name, age) VALUES ('Aseel', 31);\n",
    "INSERT INTO Ages (name, age) VALUES ('Niome', 31);\n",
    "INSERT INTO Ages (name, age) VALUES ('Niall', 19);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Once the inserts are done, run the following SQL command:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT hex(name || age) AS X FROM Ages ORDER BY X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find the first row in the resulting record set and enter the long string that looks like 53656C696E613333.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "**I follow this step and find it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "417365656C3331\n",
    "4E616E613138\n",
    "4E69616C6C3139\n",
    "4E696F6D653331"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After that put the first value to get credit for this assignment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment_15.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Counting Organizations**\n",
    "This application will read the mailbox data (mbox.txt) and count the number of email messages per organization (i.e. domain name of the email address) using a database with the following schema to maintain the counts.\n",
    "\n",
    "CREATE TABLE Counts (org TEXT, count INTEGER)\n",
    "When you have run the program on mbox.txt upload the resulting database file above for grading.\n",
    "If you run the program multiple times in testing or with dfferent files, make sure to empty out the data before each run.\n",
    "\n",
    "You can use this code as a starting point for your application: http://www.py4e.com/code3/emaildb.py.\n",
    "\n",
    "The data file for this application is the same as in previous assignments: http://www.py4e.com/code3/mbox.txt.\n",
    "\n",
    "Because the sample code is using an UPDATE statement and committing the results to the database as each record is read in the loop, it might take as long as a few minutes to process all the data. The commit insists on completely writing all the data to disk every time it is called.\n",
    "\n",
    "The program can be speeded up greatly by moving the commit operation outside of the loop. In any database program, there is a balance between the number of operations you execute between commits and the importance of not losing the results of operations that have not yet been committed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter file name: mbox.txt\n",
      "iupui.edu 536\n",
      "umich.edu 491\n",
      "indiana.edu 178\n",
      "caret.cam.ac.uk 157\n",
      "vt.edu 110\n",
      "uct.ac.za 96\n",
      "media.berkeley.edu 56\n",
      "ufp.pt 28\n",
      "gmail.com 25\n",
      "et.gatech.edu 17\n"
     ]
    }
   ],
   "source": [
    "# import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('pawan_15.2.sqlite')\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('DROP TABLE IF EXISTS Counts')\n",
    "\n",
    "cur.execute('''\n",
    "CREATE TABLE Counts (org TEXT, count INTEGER)''')\n",
    "\n",
    "fname = input('Enter file name: ')\n",
    "if (len(fname) < 1): fname = 'mbox.txt'\n",
    "fh = open(fname)\n",
    "for line in fh:\n",
    "    if not line.startswith('From: '): continue\n",
    "    pieces = line.split()\n",
    "    email = pieces[1]\n",
    "    email = line.split(\"@\")\n",
    "    email = email[1]\n",
    "    email = email.split(\"\\n\")\n",
    "    email = email[0]\n",
    "    cur.execute('SELECT count FROM Counts WHERE org = ? ', (email,))\n",
    "    row = cur.fetchone()\n",
    "    if row is None:\n",
    "        cur.execute('''INSERT INTO Counts (org, count)\n",
    "                VALUES (?, 1)''', (email,))\n",
    "    else:\n",
    "        cur.execute('UPDATE Counts SET count = count + 1 WHERE org = ?',\n",
    "                    (email,))\n",
    "    conn.commit()\n",
    "\n",
    "# https://www.sqlite.org/lang_select.html\n",
    "sqlstr = 'SELECT org, count FROM Counts ORDER BY count DESC LIMIT 10'\n",
    "\n",
    "for row in cur.execute(sqlstr):\n",
    "    print(str(row[0]), row[1])\n",
    "\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Upload this pawan_15.2.sqlite file to get credit for this assignment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WEEK_3 Data Models and Relational SQL (Chapter 15)\n",
    "**Assignment_15.3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Musical Track Database**\n",
    "This application will read an iTunes export file in XML and produce a properly normalized database with this structure:\n",
    "\n",
    "CREATE TABLE Artist (\n",
    "    id  INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,\n",
    "    name    TEXT UNIQUE\n",
    ");\n",
    "\n",
    "CREATE TABLE Genre (\n",
    "    id  INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,\n",
    "    name    TEXT UNIQUE\n",
    ");\n",
    "\n",
    "CREATE TABLE Album (\n",
    "    id  INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,\n",
    "    artist_id  INTEGER,\n",
    "    title   TEXT UNIQUE\n",
    ");\n",
    "\n",
    "CREATE TABLE Track (\n",
    "    id  INTEGER NOT NULL PRIMARY KEY \n",
    "        AUTOINCREMENT UNIQUE,\n",
    "    title TEXT  UNIQUE,\n",
    "    album_id  INTEGER,\n",
    "    genre_id  INTEGER,\n",
    "    len INTEGER, rating INTEGER, count INTEGER\n",
    ");\n",
    "If you run the program multiple times in testing or with different files, make sure to empty out the data before each run.\n",
    "\n",
    "You can use this code as a starting point for your application: http://www.py4e.com/code3/tracks.zip. The ZIP file contains the Library.xml file to be used for this assignment. You can export your own tracks from iTunes and create a database, but for the database that you turn in for this assignment, only use the Library.xml data that is provided.\n",
    "\n",
    "To grade this assignment, the program will run a query like this on your uploaded database and look for the data it expects to see:\n",
    "\n",
    "SELECT Track.title, Artist.name, Album.title, Genre.name \n",
    "    FROM Track JOIN Genre JOIN Album JOIN Artist \n",
    "    ON Track.genre_id = Genre.ID and Track.album_id = Album.id \n",
    "        AND Album.artist_id = Artist.id\n",
    "    ORDER BY Artist.name LIMIT 3\n",
    "The expected result of the modified query on your database is: (shown here as a simple HTML table with titles)\n",
    "Select Language​▼\n",
    "Track\tArtist\tAlbum\tGenre\n",
    "Chase the Ace\tAC/DC\tWho Made Who\tRock\n",
    "D.T.\tAC/DC\tWho Made Who\tRock\n",
    "For Those About To Rock (We Salute You)\tAC/DC\tWho Made Who\tRock\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict count: 404\n",
      "For Those About To Rock (We Salute You) AC/DC Who Made Who Rock\n",
      "Hells Bells AC/DC Who Made Who Rock\n",
      "Shake Your Foundations AC/DC Who Made Who Rock\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('pawan_15.3.sqlite')\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Make some fresh tables using executescript()\n",
    "cur.executescript('''\n",
    "DROP TABLE IF EXISTS Artist;\n",
    "DROP TABLE IF EXISTS Album;\n",
    "DROP TABLE IF EXISTS Track;\n",
    "\n",
    "CREATE TABLE Artist (\n",
    "    id  INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,\n",
    "    name    TEXT UNIQUE\n",
    ");\n",
    "\n",
    "CREATE TABLE Genre (\n",
    "    id  INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,\n",
    "    name    TEXT UNIQUE\n",
    ");\n",
    "\n",
    "CREATE TABLE Album (\n",
    "    id  INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,\n",
    "    artist_id  INTEGER,\n",
    "    title   TEXT UNIQUE\n",
    ");\n",
    "\n",
    "CREATE TABLE Track (\n",
    "    id  INTEGER NOT NULL PRIMARY KEY \n",
    "        AUTOINCREMENT UNIQUE,\n",
    "    title TEXT  UNIQUE,\n",
    "    album_id  INTEGER,\n",
    "    genre_id  INTEGER,\n",
    "    len INTEGER, rating INTEGER, count INTEGER\n",
    ");\n",
    "''')\n",
    "\n",
    "\n",
    "fname = \"Library.xml\"\n",
    "if ( len(fname) < 1 ) : fname = 'Library.xml'\n",
    "\n",
    "# <key>Track ID</key><integer>369</integer>\n",
    "# <key>Name</key><string>Another One Bites The Dust</string>\n",
    "# <key>Artist</key><string>Queen</string>\n",
    "def lookup(d, key):\n",
    "    found = False\n",
    "    for child in d:\n",
    "        if found : return child.text\n",
    "        if child.tag == 'key' and child.text == key :\n",
    "            found = True\n",
    "    return None\n",
    "\n",
    "stuff = ET.parse(fname)\n",
    "all = stuff.findall('dict/dict/dict')\n",
    "print('Dict count:', len(all))\n",
    "for entry in all:\n",
    "    if ( lookup(entry, 'Track ID') is None ) : continue\n",
    "\n",
    "    name = lookup(entry, 'Name')\n",
    "    artist = lookup(entry, 'Artist')\n",
    "    album = lookup(entry, 'Album')\n",
    "    genre=lookup(entry,'Genre')\n",
    "    count = lookup(entry, 'Play Count')\n",
    "    rating = lookup(entry, 'Rating')\n",
    "    length = lookup(entry, 'Total Time')\n",
    "\n",
    "    if name is None or artist is None or album is None or genre is None : \n",
    "        continue\n",
    "\n",
    "#     print(name, artist, album,genre, count, rating, length)\n",
    "\n",
    "    cur.execute('''INSERT OR IGNORE INTO Artist (name) \n",
    "        VALUES ( ? )''', ( artist, ) )\n",
    "    cur.execute('SELECT id FROM Artist WHERE name = ? ', (artist, ))\n",
    "    artist_id = cur.fetchone()[0]\n",
    "    \n",
    "    cur.execute('''INSERT OR IGNORE INTO Genre (name) \n",
    "        VALUES ( ? )''', ( genre, ) )\n",
    "    cur.execute('SELECT id FROM Genre WHERE name = ? ', (genre, ))\n",
    "    genre_id = cur.fetchone()[0]\n",
    "    \n",
    "    cur.execute('''INSERT OR IGNORE INTO Album (title, artist_id) \n",
    "        VALUES ( ?, ? )''', ( album, artist_id ) )\n",
    "    cur.execute('SELECT id FROM Album WHERE title = ? ', (album, ))\n",
    "    album_id = cur.fetchone()[0]\n",
    "\n",
    "    cur.execute('''INSERT OR REPLACE INTO Track\n",
    "        (title, album_id,genre_id, len, rating, count) \n",
    "        VALUES ( ?, ?,?, ?, ?, ? )''', \n",
    "        ( name, album_id,genre_id, length, rating, count ) )\n",
    "\n",
    "    conn.commit()\n",
    "sqlstr='SELECT Track.title, Artist.name, Album.title,Genre.name FROM Track JOIN Genre JOIN Album JOIN Artist ON Track.genre_id=Genre.ID and Track.album_id=Album.id AND Album.artist_id=Artist.id ORDER BY Artist.name LIMIT 3'\n",
    "\n",
    "for row in cur.execute(sqlstr):\n",
    "    print(str(row[0]),str(row[1]),str(row[2]),str(row[3]))\n",
    "cur.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Upload this pawan_15.3.sqlite file to get credit for this assignment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WEEK_4 Many-to-Many Relationships in SQL\n",
    "**Assignment_15.4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**\n",
    "This application will read roster data in JSON format, parse the file, and then produce an SQLite database that contains a User, Course, and Member table and populate the tables from the data file.\n",
    "\n",
    "You can base your solution on this code: http://www.py4e.com/code3/roster/roster.py - this code is incomplete as you need to modify the program to store the role column in the Member table to complete the assignment.\n",
    "\n",
    "Each student gets their own file for the assignment. Download this file and save it as roster_data.json. Move the downloaded file into the same folder as your roster.py program.\n",
    "\n",
    "Once you have made the necessary changes to the program and it has been run successfully reading the above JSON data, run the following SQL command:\n",
    "\n",
    "SELECT User.name,Course.title, Member.role FROM \n",
    "    User JOIN Member JOIN Course \n",
    "    ON User.id = Member.user_id AND Member.course_id = Course.id\n",
    "    ORDER BY User.name DESC, Course.title DESC, Member.role DESC LIMIT 2;\n",
    "The output should look as follows:\n",
    "Zian|si364|0\n",
    "Zian|si310|0\n",
    "Once that query gives the correct data, run this query:\n",
    "SELECT 'XYZZY' || hex(User.name || Course.title || Member.role ) AS X FROM \n",
    "    User JOIN Member JOIN Course \n",
    "    ON User.id = Member.user_id AND Member.course_id = Course.id\n",
    "    ORDER BY X LIMIT 1;\n",
    "You should get one row with a string that looks like **XYZZY53656C696E613333**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('XYZZY416164616D736933313030',)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('rosterdb.sqlite')\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Do some setup\n",
    "cur.executescript('''\n",
    "DROP TABLE IF EXISTS User;\n",
    "DROP TABLE IF EXISTS Member;\n",
    "DROP TABLE IF EXISTS Course;\n",
    "\n",
    "CREATE TABLE User (\n",
    "    id     INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,\n",
    "    name   TEXT UNIQUE\n",
    ");\n",
    "\n",
    "CREATE TABLE Course (\n",
    "    id     INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,\n",
    "    title  TEXT UNIQUE\n",
    ");\n",
    "\n",
    "CREATE TABLE Member (\n",
    "    user_id     INTEGER,\n",
    "    course_id   INTEGER,\n",
    "    role        INTEGER,\n",
    "    PRIMARY KEY (user_id, course_id)\n",
    ")\n",
    "''')\n",
    "\n",
    "fname = \"roster_data (3).json\"\n",
    "if len(fname) < 1:\n",
    "    fname = 'roster_data_sample.json'\n",
    "\n",
    "# [\n",
    "#   [ \"Charley\", \"si110\", 1 ],\n",
    "#   [ \"Mea\", \"si110\", 0 ],\n",
    "\n",
    "str_data = open(fname).read()\n",
    "json_data = json.loads(str_data)\n",
    "\n",
    "for entry in json_data:\n",
    "\n",
    "    name = entry[0];\n",
    "    title = entry[1];\n",
    "    role=entry[2];\n",
    "\n",
    "#     print((name, title,role))\n",
    "\n",
    "    cur.execute('''INSERT OR IGNORE INTO User (name)\n",
    "        VALUES ( ? )''', ( name, ) )\n",
    "    cur.execute('SELECT id FROM User WHERE name = ? ', (name, ))\n",
    "    user_id = cur.fetchone()[0]\n",
    "\n",
    "    cur.execute('''INSERT OR IGNORE INTO Course (title)\n",
    "        VALUES ( ? )''', ( title, ) )\n",
    "    cur.execute('SELECT id FROM Course WHERE title = ? ', (title, ))\n",
    "    course_id = cur.fetchone()[0]\n",
    "\n",
    "    cur.execute('''INSERT OR REPLACE INTO Member\n",
    "        (user_id, course_id,role) VALUES ( ?, ?, ? )''',\n",
    "        ( user_id, course_id,role ) )\n",
    "\n",
    "    conn.commit  \n",
    "test=\"\"\"SELECT 'XYZZY' || hex(User.name || Course.title || Member.role ) AS X FROM \n",
    "    User JOIN Member JOIN Course \n",
    "    ON User.id = Member.user_id AND Member.course_id = Course.id\n",
    "    ORDER BY X LIMIT 1;\"\"\"\n",
    "cur.execute(test)\n",
    "result=cur.fetchone()\n",
    "print(result)\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WEEK_5 Databases and Visualization\n",
    "**Assignment_16**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1_assignment Run this given geoload.py code and submit it's output screenshot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found in database  AGH University of Science and Technology\n",
      "\n",
      "Found in database  Academy of Fine Arts Warsaw Poland\n",
      "\n",
      "Found in database  American University in Cairo\n",
      "\n",
      "Found in database  Arizona State University\n",
      "\n",
      "Found in database  Athens Information Technology\n",
      "\n",
      "Found in database  BITS Pilani\n",
      "\n",
      "Found in database  Babcock University\n",
      "\n",
      "Found in database  Banaras Hindu University\n",
      "\n",
      "Found in database  Bangalore University\n",
      "\n",
      "Found in database  Baylor University\n",
      "\n",
      "Found in database  Beijing normal university\n",
      "\n",
      "Found in database  Belarusian State University\n",
      "\n",
      "Found in database  Belgrade University\n",
      "\n",
      "Found in database  Beloit College\n",
      "\n",
      "Found in database  Belorussian State University\n",
      "\n",
      "Found in database  Ben Gurion University\n",
      "\n",
      "Found in database  Bharthidasan University\n",
      "\n",
      "Found in database  Boston University\n",
      "\n",
      "Found in database  Budapesti Corvinus Egyetem\n",
      "\n",
      "Found in database  California Polytechnic State University of San Luis Obispo\n",
      "\n",
      "Retrieving https://maps.googleapis.com/maps/api/geocode/json?address=California+State+University+San+Bernardino&key=AIzaSyD9z8vvTzJzjSbTXyR082e7BzUWQsimj-w\n",
      "Retrieved 256 characters {    \"error_message\"\n",
      "==== Failure To Retrieve ====\n",
      "{\n",
      "   \"error_message\" : \"You must enable Billing on the Google Cloud Project at https://console.cloud.google.com/project/_/billing/enable Learn more at https://developers.google.com/maps/gmp-get-started\",\n",
      "   \"results\" : [],\n",
      "   \"status\" : \"REQUEST_DENIED\"\n",
      "}\n",
      "\n",
      "Run geodump.py to read the data from the database so you can vizualize it on a map.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "import http\n",
    "import sqlite3\n",
    "import json\n",
    "import time\n",
    "import ssl\n",
    "import sys\n",
    "\n",
    "#--- Initialising\n",
    "api_key = 'AIzaSyD9z8vvTzJzjSbTXyR082e7BzUWQsimj-w' #False\n",
    "# If you have a Google Places API key, enter it here\n",
    "# api_key = 'AIzaSy___IDByT70'\n",
    "\n",
    "if api_key is False:\n",
    "    serviceurl = \"http://py4e-data.dr-chuck.net/geojson?\"\n",
    "else :\n",
    "    serviceurl = \"https://maps.googleapis.com/maps/api/geocode/json?\" #place/textsearch/json?\"\n",
    "\n",
    "# Additional detail for urllib\n",
    "# http.client.HTTPConnection.debuglevel = 1\n",
    "\n",
    "#--- Opening connection to the SQLite database\n",
    "conn = sqlite3.connect('geodata.sqlite')\n",
    "cur = conn.cursor()\n",
    "\n",
    "#--- Initialising database\n",
    "cur.execute('''\n",
    "CREATE TABLE IF NOT EXISTS Locations (address TEXT, geodata TEXT)''')\n",
    "\n",
    "#--- Ignoring SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "#--- Opening connection to the data file\n",
    "fh = open(\"where.data\")\n",
    "count = 0\n",
    "#--- Looping through the data file by 200 lines at a time\n",
    "for line in fh:\n",
    "    if count > 200 :\n",
    "        print('Retrieved 200 locations, restart to retrieve more')\n",
    "        break\n",
    "\n",
    "    #--- Getting the geodata of the address from the database\n",
    "    address = line.strip()\n",
    "    print('')\n",
    "    cur.execute(\"SELECT geodata FROM Locations WHERE address= ?\",\n",
    "        (memoryview(address.encode()), ))\n",
    "\n",
    "    #--- ... and printing message if geodata is already in the database\n",
    "    try:\n",
    "        data = cur.fetchone()[0]\n",
    "        print(\"Found in database \",address)\n",
    "        continue\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #--- Constructing the encoded URL using the address and the API key\n",
    "    parms = dict()\n",
    "    parms[\"address\"] = address #parms[\"query\"] = address\n",
    "    if api_key is not False: parms['key'] = api_key\n",
    "    url = serviceurl + urllib.parse.urlencode(parms)\n",
    "\n",
    "    #--- Printing the URL for the user's convenience\n",
    "    print('Retrieving', url)\n",
    "    \n",
    "    #--- Submitting the service request by opening the URL\n",
    "    uh = urllib.request.urlopen(url, context=ctx)\n",
    "    data = uh.read().decode()\n",
    "    #--- Printing the first 20 characters of the result\n",
    "    print('Retrieved', len(data), 'characters', data[:20].replace('\\n', ' '))\n",
    "    count = count + 1\n",
    "\n",
    "    #--- Loading the received result in as JSON object or printing an error message\n",
    "    try:\n",
    "        js = json.loads(data)\n",
    "    except:\n",
    "        print(data)  # We print in case unicode causes an error\n",
    "        continue\n",
    "\n",
    "    #--- Printing an error message if something is wrong with the status\n",
    "    if 'status' not in js or (js['status'] != 'OK' and js['status'] != 'ZERO_RESULTS') :\n",
    "        print('==== Failure To Retrieve ====')\n",
    "        print(data)\n",
    "        break\n",
    "\n",
    "    #--- Adding the received result into the SQLite database\n",
    "    cur.execute('''INSERT INTO Locations (address, geodata)\n",
    "            VALUES ( ?, ? )''', (memoryview(address.encode()), memoryview(data.encode()) ) )\n",
    "    conn.commit()\n",
    "    \n",
    "    #--- Adding a delay at every 10 request\n",
    "    if count % 10 == 0 :\n",
    "        print('Pausing for a bit...')\n",
    "        time.sleep(1)\n",
    "\n",
    "#--- Printing a message at the end to continue with dumping the data using 'geodump.py'\n",
    "print(\"Run geodump.py to read the data from the database so you can vizualize it on a map.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2_assignment Run this given geodump.py code and submit it's output screenshot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aleja Adama Mickiewicza 30, 30-059 Kraków, Poland 50.06688579999999 19.9136192\n",
      "Krakowskie Przedmieście 5, 00-068 Warszawa, Poland 52.2394019 21.0150792\n",
      "Cairo، محافظة القاهرة‬ 11835, Egypt 30.018923 31.499674\n",
      "1475 N Scottsdale Rd, Scottsdale, AZ 85257, USA 33.4641541 -111.9231478\n",
      "Monumental Plaza, Building C, 1st Floor, Leof. Kifisias 44, Marousi 151 25, Greece 38.0399391 23.8030901\n",
      "VidyaVihar Campus, Pilani, Rajasthan 333031, India 28.3639976 75.58696809999999\n",
      "Ilishan Remo Ogun State Nigeria, ILISHAN REMO, Nigeria 6.8919631 3.7186605\n",
      "Ajagara, Banaras Hindu University Campus, Varanasi, Uttar Pradesh 221005, India 25.2677203 82.99125819999999\n",
      "Mysore Road, Jnana Bharathi, Bengaluru, Karnataka 560056, India 12.9503878 77.5022224\n",
      "1301 S University Parks Dr, Waco, TX 76706, USA 31.549841 -97.1143146\n",
      "19 Xinjiekou Outer St, BeiTaiPingZhuang, Haidian Qu, Beijing Shi, China, 100875 39.9619537 116.3662615\n",
      "praspiekt Niezaliežnasci 4, Minsk, Belarus 53.8930389 27.5455567\n",
      "Studentski trg 1, Beograd, Serbia 44.8184339 20.4575676\n",
      "700 College St, Beloit, WI 53511, USA 42.5030333 -89.0309048\n",
      "praspiekt Niezaliežnasci 4, Minsk, Belarus 53.8930389 27.5455567\n",
      "שד בן-גוריון 1, באר שבע, Israel 31.262218 34.801461\n",
      "Palkalaiperur, Tiruchirappalli, Tamil Nadu 620024, India 10.6779085 78.74454879999999\n",
      "Boston, MA 02215, USA 42.3504997 -71.1053991\n",
      "Budapest, Fővám tér 8., 1093 Hungary 47.486135 19.057964\n",
      "San Luis Obispo, CA 93407, USA 35.3050053 -120.6624942\n",
      "20 records written to where.js\n",
      "Open where.html to view the data in a browser\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import json\n",
    "import codecs\n",
    "\n",
    "#--- Opening connection to the SQLite database\n",
    "conn = sqlite3.connect('geodata.sqlite')\n",
    "cur = conn.cursor()\n",
    "\n",
    "#--- Reading everything from the database into the cursor\n",
    "cur.execute('SELECT * FROM Locations')\n",
    "\n",
    "#--- Opening javascript file for writing data for visualisation\n",
    "fhand = codecs.open('where.js', 'w', \"utf-8\")\n",
    "fhand.write(\"myData = [\\n\")\n",
    "count = 0\n",
    "\n",
    "#--- Looping through all the data read from the database\n",
    "for row in cur :\n",
    "    #--- Transforming and loading the data into a JSON object\n",
    "    data = str(row[1].decode())\n",
    "    try: js = json.loads(str(data))\n",
    "    except: continue\n",
    "\n",
    "    #--- Checking if the status is all right\n",
    "    if not('status' in js and js['status'] == 'OK') : continue\n",
    "\n",
    "    #--- Getting the latitude, longitude and the formatted address\n",
    "    lat = js[\"results\"][0][\"geometry\"][\"location\"][\"lat\"]\n",
    "    lng = js[\"results\"][0][\"geometry\"][\"location\"][\"lng\"]\n",
    "    if lat == 0 or lng == 0 : continue\n",
    "    where = js['results'][0]['formatted_address']\n",
    "    where = where.replace(\"'\", \"\")\n",
    "    \n",
    "    #--- Printing the latitude, longitude and the formatted address\n",
    "    try :\n",
    "        print(where, lat, lng)\n",
    "\n",
    "        count = count + 1\n",
    "        if count > 1 : fhand.write(\",\\n\")\n",
    "        output = \"[\"+str(lat)+\",\"+str(lng)+\", '\"+where+\"']\"\n",
    "        fhand.write(output)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "#--- Finishing writing into the javascript file and closing the file\n",
    "fhand.write(\"\\n];\\n\")\n",
    "cur.close()\n",
    "fhand.close()\n",
    "\n",
    "#--- Printing the number of records written into the javascript file and a message\n",
    "#--- to continue with visualisation of the data in 'where.html'\n",
    "print(count, \"records written to where.js\")\n",
    "print(\"Open where.html to view the data in a browser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3_assignment Run this given where.html code and submit it's output screenshot**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check my Accomplishment** link:- https://www.coursera.org/account/accomplishments/verify/3KWKS94C6NPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This course will introduce students to the basics of the Structured Query Language (SQL) as well as basic database design for storing data as part of a multi-step data gathering, analysis, and processing effort.  The course will use SQLite3 as its database.  We will also build web crawlers and multi-step data gathering and visualization processes.  We will use the D3.js library to do basic data visualization.  This course will cover Chapters 14-15 of the book “Python for Everybody”. To succeed in this course, you should be familiar with the material covered in Chapters 1-13 of the textbook and the first three courses in this specialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
